{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 28 - Algorithmic Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Python language has been introduced more or less in its entirety, it becomes prevalent to discuss how to use this language (or any other computer language) most effectively. Effective programming entails that programs are designed of low computational complexity. The two main areas of complexity that an algorithm touches are space complexity and time complexity. Space complexity considers how much space an algorithm needs to run. Time complexity considers how speedy it is. In general, space complexity is not considered of much importance (unless it is exceptionally degenerate), but time complexity is. In this chapter, I will discuss how the time complexity of algorithms can be compared.\n",
    "\n",
    "I wish to add up front that I still think that your first priority should be to get a program to work, not to get it to work most efficiently. However, it is good to be able to have insight in exactly how efficient your algorithms are, so that you may get an idea of whether it might be a valuable task to try to improve their efficiency. This chapter provides you with initial knowledge to gain such insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that I have two competing algorithms for sorting a list of numbers. I test each of them on the same list of 10 numbers. Algorithm 1 needs double the time of Algorithm 2. Which algorithm do I prefer?\n",
    "\n",
    "The answer is: I don't know. If the only thing the algorithm needs to do is sorting that specific list of 10 numbers, then obviously Algorithm 2 is preferable, but if I only have one list of numbers to sort, I don't need an algorithm at all. I can just use the sorted version of the list. I design algorithms to deal with general classes of problems. A sorting algorithm needs to be able to sort any sequence of numbers. To determine which algorithm is most time efficient in this, I need more tests. Better yet, I need to analyse the algorithm's code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big-O notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To express the time complexity of an algorithm, computer scientists use the so-called \"big-O notation\" (you can use big-O notation just as well to express space complexity, but in general it is used for time complexity). Big-O notation indicates an algorithm's time complexity in terms of the size of the variables which it depends on. For instance, for a sorting algorithm it expresses it in terms of `n`, whereby `n` is the size of the list that gets sorted. Big-O notation shows how the speed of the algorithm changes as a function of `n` in a worst-case scenario. More specifically, it indicates an \"upper bound\" to the time complexity of the algorithm.\n",
    "\n",
    "For instance, if an algorithm is `O(n)`, it means that the time needed for the algorithm to do its work has an upper bound that is a linear function of `n`, whereby `n` is some variable that has relevance for the algorithm. For instance, for an algorithm that deals with list, `n` could represent the length of the list. For the algorithm to be `O(n)`, it would mean that, for example, the difference in time needed for dealing with a list of 10 numbers and dealing with a list of 20 numbers, is about the same as the difference in time needed for dealing with a list of 30 numbers and dealing with a list of 40 numbers. \n",
    "\n",
    "In comparison, the algorithm being `O(n`&sup2;`)` indicates that the time needed for it to do its work has an upper bound that is a quadratic function of `n`. The time needed in this case increases much faster with an increase of `n` than in the case of `O(n)`. This means that, in general, if I can choose between an algorithm that is `O(n)` and one that is `O(n`&sup2;`)`, I prefer the first.\n",
    "\n",
    "It might be that the first algorithm still needs a lot more time than the second algorithm to deal with, say, a list of 1000 numbers or less. However, I know that, if the list increases, at some point the first algorithm will be faster than the second. I also know that the longer the list grows, the more time the first algorithm will gain in comparison with the second.\n",
    "\n",
    "In general, when expressing time complexity using big-O notation, only the most influential term is taken into account. E.g., an algorithm that needs `5n`&sup2;`+3n+7` seconds to run, is considered to be `O(n`&sup2;`)`. The other terms and the constant factors are ignored. The reason is, that given a large enough `n`, the other terms are negligible. You might think that the constant with which the `n`&sup2; is multiplied (5 in this case) is still relevant, but it is not, as the exact time that is needed to run the algorithm depends on many constants, for instance, relating to the hardware used. Therefore multiplying by a constant is meaningless.\n",
    "\n",
    "Naturally, if there are two competing algorithms with the *same* big-O, to choose between them the constants and other terms do play a role, and you have to compare the algorithms using examples, or more extensive analysis.\n",
    "\n",
    "Note 1: Technically, big-O notation indicates a *set* of functions. Therefore it is appropriate to say that an algorithm is *in* `O(g)` (where `g` is a function that is representative as an upper bound to the time complexity of the algorithm). However, in practice people talk about such complexities a bit sloppily, and simply say that an algorithm \"is `O(n)`\", rather than \"the time complexity of the algorithm is in `O(n)`.\" I will use the sloppy speak here too, as that is what is common.\n",
    "\n",
    "Note 2: Theoretically, an algorithm that is `O(n)` is *also* `O(n`&sup2;`)`. The reason is that `O(n)` indicates a smaller time complexity than `O(n`&sup2;`)`, and the big-O notation indicates *some upper bound* to the time complexity. However, in practice big-O notation is simply used as the lowest indication for the worst-case scenario. Therefore, an algorithm that is `O(n)` would not be indicated as being `O(n`&sup2;`)`, even if theoretically that is true. So, if I say that an algorithm is of a particular big-O, I mean (just like everybody else) that this is the lowest indication for the time complexity in the worst-case scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Consider three algorithms with equal functionality. The first is `O(n`&sup2;`)`, the second `O(n*`&radic;`n)`, and the third `O(n*log(n))`. Which would you prefer on the basis of this information? Which seems to be the least preferable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: Examine the graph below, in which typical interpretations of the three functions are shown.\n",
    "\n",
    "<img src=\"img/complexity.png\" alt=\"Comparing three functions\" style=\"width:600px;\"><br>\n",
    "<div align=\"center\">Figure 28.1: Comparing three functions.</div>\n",
    "\n",
    "What you can observe here (and what a mathematical analysis will confirm) is that `n`&sup2; increases much faster than both `n*`&radic;`n` and `n*log(n)`. Moreover, `n*`&radic;`n` increases faster than `n*log(n)`. Therefore, the algorithm which is `O(n`&sup2;`)` is least preferable, and the algorithm which is `O(n*log(n))` is most preferable.\n",
    "\n",
    "At first glance, you might think that you need to know more about the exact time needed. For instance, suppose that the second algorithm needs about `n*`&radic;`n` seconds to run, while the third needs `10*n*log(n)` seconds. In that case, the big-O's are as given, but in the graph `10*n*log(n)` will rise much steeper than the other sequences. However, that is only at the start -- in the graph, you can see that the sequence for `n*`&radic;`n` bends slightly upward, while `n*log(n)` is almost a straight line. Therefore, given a high enough `n`, `10*n*log(n)` will be lower than `n*`&radic;`n` (you can check this mathematically, and determine when one function intersects the other; you will find an answer close to `n=8100`).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other notations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notations that are related to big-O notation are big-Omega (&Omega;) and big-Theta (&Theta;) notations. \n",
    "\n",
    "Big-Omega indicates the time-complexity of the best-case scenario. In general, algorithms cannot expect to deal with the best case, so big-Omega is not often used, unless it is to indicate the lower boundary of the time complexity. E.g., one might say that an algorithm is between &Omega;`(n`&sup2;`)` and `O(n`&sup3;`)`. For computer scientists, however, only the upper bound tends to be relevant.\n",
    "\n",
    "Big-Theta indicates the \"tight bound\" time complexity. This entails the following: If there is a function `g` for which it holds that for sufficiently large values for the variables which `g` depends on, the time complexity of an algorithm is between `c`<sub>1</sub>`*g` and `c`<sub>2</sub>`*g`, where `c`<sub>1</sub> and `c`<sub>2</sub> are constants, then the \"tight bound\" time complexity of the algorithm is &Theta;`(g)`. Automatically, this entails that the algorithm is also `O(g)` and &Omega;`(g)`. This also means that if for an algorithm the optimal functions for big-O and big-Omega are different, there is no big-Theta, while if they are the same, that is also big-Theta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text above may have given the impression that `n` always refers to the size of a list of numbers. Naturally, that is not the case. `n` is a variable that refers to *something* that influences the time complexity of the algorithm. For instance, in the case of an algorithm that tests whether a number is prime, `n` may simply refer to the number (as you can imagine that the time complexity of a prime-tester increases with the size of the number that is being tested). Moreover, it is possible that the time complexity of an algorithm is depended on multiple variables. If that is the case, these variables each get their own symbol in the big-O expression. It is, for instance, common to have both an `m` and an `n`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here follow multiple exercises which ask you to determine the time complexity of an algorithm. The answers are given in the text, as the exercises should teach you how to think about time complexity and how to determine it. I recommend that you try to solve each of the exercises by yourself before studying the answers given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: What is the time complexity of the following algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( 3.14 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: There is no variable that influences the time needed to run a program that simply prints the value 3.14. In other words, this program runs in constant time. Thus, we say that it is `O(1)`.\n",
    "\n",
    "As indicated above, there is no need to determine exactly how fast the algorithm runs. The value of the constant in the big-O expression does not matter; `O(2)` is the same as `O(1)`, which is the same as `O(0.5)`. As long as the constant is a positive value, all these expressions are the same (naturally, `O(0)` would be silly, because it would refer to an algorithm that needs no time at all). By convention, we refer to the time complexity of an algorithm that runs in constant time as `O(1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: What is the time complexity of the function `select_random()` in the following piece of code? You may assume that `n` refers to the length of the list which is supplied as a variable to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def select_random( numlist ):\n",
    "    num = randint( 0, len( numlist )-1 )\n",
    "    return numlist[num]\n",
    "\n",
    "print( select_random( [ 0, 4, 7, 10, -99, -3, 8 ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: While this function uses a list, the actual length of the list does not matter for the time complexity of the algorithm. One number is randomly determined, and one element of the list is returned. That is all. Therefore the time complexity is `O(1)`.\n",
    "\n",
    "You might think that the length of the list still influences the speed of the function somewhat. Maybe it is faster to select an item from a list that has only 10 items, than that it is to select an item from a list that has several millions of items. And you are probably right, it is likely that long lists need more processing time than short lists, even if it is just to pick a number of the list. However, for the complexity of the algorithm that does not matter; these issues are related to hardware. The algorithm simply takes two steps: (1) pick a random number, and (2) return the value with the corresponding index, which is a direct look-up (i.e., the computer knows exactly at what memory address it can find the value). The algorithm always needs these two steps, and no more, and therefore its time complexity is constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: The function `print_list()` prints all items from a list. What is the time complexity of this function? You may assume that `n` refers to the length of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_list( tlist ):\n",
    "    for item in tlist:\n",
    "        print( item )\n",
    "        \n",
    "print_list( [ 0, 5, 8, 7.5, 20, 20, 88 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: The function needs as many steps as there are items on the list. Its time complexity is therefore linear with the length of the list, or `O(n)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: The function `print_some_items()` prints items from a list. It will begin at the start of the list, and will continue printing items until it reaches the end of the list or encounters a zero. If that happens, it stops printing. What is the time complexity of this function? You may assume that `n` refers to the length of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_some_items( tlist ):\n",
    "    for item in tlist:\n",
    "        if item == 0:\n",
    "            return\n",
    "        print( item )\n",
    "        \n",
    "print_some_items( [ 99, 4, 0, 5, 8, 7.5, 20, 20, 88 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: Remember that time complexity in big-O notation considers the worst-case scenario. The worst-case scenario is that no zero occurs on the list, and thus all items need to be printed. Therefore this exercise is no different from the previous one, and thus the time complexity of the function is `O(n)`.\n",
    "\n",
    "Note that in the function `print_some_items()` two steps are taken for every item, namely (1) testing whether the item is zero, and (2) printing the item. In the function `print_list()` only one of these steps is taken, namely printing the item. Objectively, therefore, `print_some_items()` will always be slower than `print_list()` (if there is no zero in the list). However, that does not matter for the time complexity. If every step would take one unit of time, then `print_some_items()` would need `2n` time units, while `print_list()` would only need `n` time units. However, since `O(2n)` is equal to `O(n)`, the time complexities of the two functions are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: The function `check_prime()` checks if a number `n` is prime. This algorithm has been discussed several times before. Note that the function does not check all possible divisors between 2 and the number `n`, but only checks up to the number that, when squared, exceeds `n`. What is the time complexity of this function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_prime( n ):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    i = 2\n",
    "    while i*i <= n:\n",
    "        if n%i == 0:\n",
    "            return False\n",
    "        i += 1\n",
    "    return True\n",
    "\n",
    "num = 3117421\n",
    "if check_prime( num ):\n",
    "    print( num, \"is prime\" )\n",
    "else:\n",
    "    print( num, \"is not prime\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: We need to consider the worst-case scenario, which is calling the function with a number `n` that is prime, as in that case the most divisors need to be checked. Note that we only need to check the divisors up to the square root of `n`. This means that the time complexity of the function is `O(`&radic;`n)`.\n",
    "\n",
    "You may calculate this step by step. For instance, you may consider that each step need 1 unit of time. So testing whether `n` is smaller than 2 takes 1 time unit, initializing `i` takes 1 time unit, and then for all numbers between 2 and (about) &radic;`n` we need another 2 steps (testing whether `n` is divisible by `i`, and adding 1 to `i`). Finally, we need 1 time step to return from the function. Adding this all up, we need `3 + 2*`&radic;`n` time steps. Since `O(3 + 2*`&radic;`n)` is equal to `O(`&radic;`n)`, `O(`&radic;`n)` is the answer.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: The `check_prime_smart()` function is smarter in checking whether a number is prime than the previous `check_prime()` function, as it skips all even numbers. What is the time complexity of this function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_prime_smart( n ):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        return True\n",
    "    if n%2 == 0:\n",
    "        return False\n",
    "    i = 3\n",
    "    while i*i <= n:\n",
    "        if n%i == 0:\n",
    "            return False\n",
    "        i += 2\n",
    "    return True\n",
    "\n",
    "num = 3117421\n",
    "if check_prime_smart( num ):\n",
    "    print( num, \"is prime\" )\n",
    "else:\n",
    "    print( num, \"is not prime\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: `check_prime_smart()` needs more or less half the time of `check_prime()`. Therefore, if `check_prime()` needs &radic;`n` time, then `check_prime_smart()` needs `(1/2)*`&radic;`n` time. Since `O((1/2)*`&radic;`n)` is equal to `O(`&radic;`n)`, the time complexity of `check_prime_smart()` is the same as the time complexity of `check_prime()`. Still, if you had to choose between the two algorithms, `check_prime_smart()` is probably the preferred choice, as it is about twice as fast as `check_prime()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun fact: `O(`&radic;`n)` is not the optimal time complexity for a prime tester. The AKS algorithm for prime testing, designed in 2002 by Agrawal, Kayal, and Saxena, is `O(log(n)`<sup>6</sup>`)`. As yet, it is unknown whether this is optimal, but it probably is not. Possible improvements have been suggested but are based on theorems of which it is unknown whether they are true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: `check_sorted_list()` checks if a number occurs on a *sorted* list of numbers. You may assume that the function is always called with a sorted list of numbers. The function is smart, as it is not just going through all numbers on the list, but jumps through the list in a smart way. It reduces the size of the list quickly, by halving it every time it checks a number (this is called a \"binary search\", by the way, which will be discussed in the next chapter). What is the time complexity of this function? You may consider `n` to be the length of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_sorted_list( numlist, num ):\n",
    "    low = -1\n",
    "    high = len( numlist )\n",
    "    while low < high-1:\n",
    "        middle = round( (low + high)/2 )\n",
    "        if numlist[middle] == num:\n",
    "            return True\n",
    "        elif numlist[middle] < num:\n",
    "            low = middle\n",
    "        else:\n",
    "            high = middle\n",
    "    return False\n",
    "    \n",
    "numlist = [0, 4, 5, 6, 7, 9, 12, 25, 26, 27, 28, 45, 46, 48, 50, 55, 60, 65, 79, 80, 82, 85, 93, 100]\n",
    "for num in range( 0, 101, 5 ):\n",
    "    if check_sorted_list( numlist, num ):\n",
    "        print( num, \"is on the list\" )\n",
    "    else:\n",
    "        print( num, \"is not on the list\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: Consider what happens in this algorithm (you do not even need to look at the code, as I described above what the algorithm does). The worst-case scenario is that the number that is sought is not on the list. The algorithm will then halve the list again and again, until the list has size 1, and the number is not found. This means that if the list contains 64 items, then first it will check the middle number of a list of 64 items, then the middle number of a list of 32 items, then the middle number of a list of 16 items, then the middle of 8, the middle of 4, of 2, and finally of 1. I.e., for a list of length 2<sup>m</sup> it does about `m` checks (actually `m+1` checks, but you probably have learned by now that for these big-O considerations, adding a constant changes nothing). This entails that for a list of length `n`, `log`<sub>2</sub>`(n)` steps are needed, i.e., its time complexity is `O(log`<sub>2</sub>`(n))`. The base 2 in this case does not matter (the only importance is that time complexity increases logarithmically), which entails that we write this time complexity as `O(log(n))` (i.e., the natural logarithm -- this is simply convention)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: As a diversion, can you determine the big-Omega expression for the `check_sorted_list()` function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: Big-Omega indicates the time needed for the best-case scenario. For the `check_sorted_list()` function, the best-case scenario is that the first item that you check immediately is the item that you were looking for. This means that in the best-case scenario, only 1 time step is needed, regardless of the length of the list. So the lower bound for the time complexity is &Omega;`(1)`. That is rather uninformative, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: The algorithm above is called with a sorted list. What if the list is not sorted, and the function calls `numlist.sort()` as the first line to sort it? Does this change the time complexity? If so, in what way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: This may definitely change the time complexity, but how depends on the time complexity of the `sort()` method. While this method is only called once, we may assume that its time needs increase with the length of the list, and thus that the `sort()` function is not `O(1)`. How much the time needs increase depends on how the method was implemented. Its time complexity is probably `O(n*log(n))` (a future chapter will explain this). This means that the time complexity of the `check_sorted_list()` function becomes `O(n*log(n) + log(n))`, which, since the first term is dominant here, is `O(n*log(n))`.\n",
    "\n",
    "Make sure that when you try to determine the time complexity of an algorithm, you are not counting the call of standard functions and methods as simply needing 1 time unit when they depend on something for which the size may change. You will have to determine how these standard functions and methods work before you can actually determine the time complexity of your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, you learned about:\n",
    "\n",
    "- Time complexity\n",
    "- Big-O notation (`O`)\n",
    "- Big-Omega notation (&Omega;)\n",
    "- Big-Theta notation (&Theta;)\n",
    "- Determining time complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 28.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the time complexity of the `print_string()` function in the following program?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_string( s ):\n",
    "    print( s )\n",
    "\n",
    "print_string( \"Hello, world!\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 28.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the time complexity of the `sum_nums()` function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_nums( numlist ):\n",
    "    total = 0\n",
    "    for num in numlist:\n",
    "        total += num\n",
    "    return total\n",
    "\n",
    "print( sum_nums( [1, 3, 5, 7, 9, 11, 13, 15] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 28.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the function `dump_list()` below. If the number of items on the list is even, it prints all the items. If the number is odd, it prints all the items of the list as often as the list is long. Express the time complexity of this function in big-O notation and in big-Omega notation. Can you also determine the big-Theta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_list( tlist ):\n",
    "    if len( tlist )%2 == 0:\n",
    "        for item in tlist:\n",
    "            print( item, end=\" \" )\n",
    "        print()\n",
    "    else:\n",
    "        for i in range( len( tlist ) ):\n",
    "            for item in tlist:\n",
    "                print( item, end=\" \" )\n",
    "            print()\n",
    "            \n",
    "dump_list( [\"apple\", \"banana\", \"cherry\", \"peach\"] )\n",
    "dump_list( [\"apple\", \"banana\", \"cherry\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 28.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you find two functions which determine the largest number on a list of numbers. Which do you prefer? Consider big-O, big-Omega, and big-Theta of both functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_largest_1( numlist ):\n",
    "    if len( numlist ) <= 0:\n",
    "        return \"empty\"\n",
    "    for i in range( len( numlist ) ):\n",
    "        for j in range( i+1, len( numlist ) ):\n",
    "            if numlist[i] < numlist[j]:\n",
    "                break\n",
    "        else:\n",
    "            return numlist[i]\n",
    "    return( numlist[-1] )\n",
    "\n",
    "def get_largest_2( numlist ):\n",
    "    if len( numlist ) <= 0:\n",
    "        return \"empty\"\n",
    "    n = numlist[0]\n",
    "    for i in range( 1, len( numlist ) ):\n",
    "        if numlist[i] > n:\n",
    "            n = numlist[i]\n",
    "    return n\n",
    "        \n",
    "numlist = [0,1,2,5,3,5,6,7,4,4,-1,3,0,2]\n",
    "print( get_largest_1( numlist ) )\n",
    "print( get_largest_2( numlist ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 28.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider an algorithm that needs `log(n)` seconds to run (based on some data structure of size `n` that it processes). Which of the following statements on this algorithm are true?\n",
    "\n",
    "- It is `O(n`&sup2;`)`\n",
    "- It is `O(n)`\n",
    "- It is `O(`&radic;`n)`\n",
    "- It is `O(log(n))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 28.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last exercise in the chapter on Iterations gives three algorithms for calculating the average life span of Triangle Crawlers. I will not repeat these algorithms here, as you may still want to do that exercise (it is one of the hardest ones of that chapter, so you may have skipped it). What is the time complexity in big-O notation of each of the answers that I provided, whereby `n` is the number of Triangle Crawlers?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Chapter 28. Version 1.1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
